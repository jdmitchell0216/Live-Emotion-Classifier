# Live-Emotion-Classifier
Justin Mitchel, Kevin Zhao

This project uses neural networks to train a model to understand 7 human emotions: anger, disgust, fear, happy, neutral, sad, surprise. This model uses transfer learning mode, VGG16, and two labeled datasets of emotions to classify what a person's emotion is given an expression. This was incorporated into the package opencv in order to be able to produce a live video feed and classification as soon as someone shows an expression on camera,


# Project Title

One Paragraph of project description goes here

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

What things you need to install the software and how to install them

```
Give examples
```

### Installing

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

## Deployment

Add additional notes about how to deploy this on a live system

## Built With

* [OpenCV](https://docs.opencv.org/4.1.0/) - Face detection and live video capture
* [keras](https://keras.io/) - Construction of models
* [sklearn](https://scikit-learn.org/stable/whats_new.html) - Model preparation and evaluation
* [Google CoLabs](https://colab.research.google.com/notebooks/welcome.ipynb) - Environment used for training the models

## Authors

* **Justin Mitchell** - *Initial work* - [GitHub](github.com/jdmitchell0216)
* **Kevin Zhao** - *Initial work* - [GitHub](github.com/kevzha)

